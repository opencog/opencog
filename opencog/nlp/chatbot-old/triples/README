
                          Semantic Triples
                          ----------------
                      Linas Vepstas January 2009

This directory contains some experimental code to extract "semantic
triples" from English text.  A semantic triple is a triple of 
subject-relation-object, and is popularly the topic of "Semantic Web
RDF" technology discussions[WP-RDF].  An example of a "semantic triple"
is "the sky is blue". Written in prefix notation, the triple is then 
"color_of(sky, blue)", with "color_of" being the property or predicate,
while "sky" and "blue" are the subject and object, respectively. In the
industry, this task is sometimes refered to as "WIE" or "Web Information
Extraction"; it is also sometimes called "linguistic reification".

One reason for creating semantic triples is that it simplifies certain
types of deductions and inferences. For example, "author_of('Pride and 
Prejudice', 'Jane Austen')" and "wrote('Pride and Prejudice', 'Jane 
Austen')" are more or less synonymous expressions. Normalizing more
complex structures (such as the output of RelEx, or of dependency 
parsers in general), make it considerably easier to automatically
discover such synonymous expressions. This is an important point: the
triples extraction process does not create new information; it just
makes given classes of hypergraphs easier to work with.

There is a major semantic distinction between "prepositional relations"
and "action" or "verbing" relations. So, for example, "next_to(house, tree)"
is a prepositional relation, while "throw(John,rock)" is an action 
relation. Roughly speaking, prepositional relations hold over extended 
periods of time (the tree and house are not likely to move anytime soon)
while verb/action relations hold only during instants in time (once the
throwing is done, it becomes something that happened in the past). This
distinction is important when performing common-sense reasoning.

The primary challenge here is of dealing with the diversity of
expression in the English language, where most sentences are NOT short,
to-the-point assertions that something is true. For short, simple
sentences, RelEx seems to provide enough normalization to extract at
least some triples. But it is not clear how far this idea (of using
triples) can be pushed.

For the most part, the above challenge is ignored here; it is pursued
in greater detail in the nlp/seme/README. Instead, a more concrete set
of tasks are set out and solved here: 

1) How to represent semantic triples within OpenCog.
2) How to extract basic semantic triples from straightforward, 
   unambiguous RelEx input.

The result is the defintion of an IF..THEN.. syntax that can be converted
to OpenCog ImplicationScopeLinks, and then used (via the query system) to
process RelEx input and generate triples output.  The IF..THEN.. syntax
very closely resembles that used by the RelEx framing code, with the 
intention that someday, it will be possible to use this code to port the
RelEx frame processing to OpenCog.


Status
------
The experiment was concluded in 2009 and the code here is mothballed.
Here's what I learned: it appears that the syntactic structure of the
English language is important for reasoning and understanding, and that
simplifications, such as those done here, can erase important semantic
content.  

The code here uses a design decision that makes it unappealing to
further extend this work, at least, not without re-writing a core part
of it.  Specifically, the issue is the reduction of a sentence such as
"John threw a rock" to the triple "throw(John,rock)".  The begs a
question: if the input sentence is "John threw a rock at the window",
how should that be represented?  The answer is clear when the subject
and object at maintained distinctly:  "_subj(throw, John) _obj(throw,
rock) at(rock, window)".  But when the triple is "throw(John,rock)"
its no longer clear how to attach "at the window" to this structure.
Unfortunately, the code here generates these triples, and the problem
is not easily fixable without a fairly major tearup.  To reiterate:
synatactic relations are ignored at one's peril.

As to the practical usability of this code: there are other issues,
described below, and especially the to-do section, that require
attention.


Structures
----------
Triples are to follow the existing opencog predicate structure:

   (EvaluationLink
      (ConceptNode "color_of")
      (ListLink
         (ConceptNode "sky")
         (ConceptNode "blue")
      )
   )

is an example of what would be deduced from the copula "The color of the
sky is blue". This example is somewhat over-simplified; this is
addressed later.

Simple Example Sentences
-------------------------
First, consider some input sentences:

Input sentence: "The capital of Germany is Berlin."
RelEx output: 
_subj(be, capital)
_obj(be, Berlin)
of(capital, Germany)

Input sentence: "Berlin is the capital of Germany."
_subj(be, Berlin)
_obj(be, capital)
of(capital, Germany)

Input sentence: "The color of the sky is blue."
of(color, sky)
_predadj(color, blue)

Input sentence: "Pottery is made from clay."
_obj(make, pottery)
from(make, clay)

Input sentence: "Yarn is spun from fibers."
_obj(spin, yarn)
from(spin, fibers)

Input sentence: "Yarn is made of fibers."
_obj(made_of, yarn)
_iobj(made_of, fibers)

Input sentence: "Berlin is in Germany."
The more highly ranked parse gives:
in(_%copula, in)
_pobj(in, Germany)
_psubj(in, Berlin)

A second, but lower-ranked parse, gives:
in(be, Germany)
_subj(be, Berlin)

Input sentence: "Berlin is a city in Germany."
in(be, Germany)
_subj(be, Berlin)
_obj(be, city)

A second, but lower-ranked parse, gives:
in(city, Germany)
_subj(be, Berlin)
_obj(be, city)

Clearly, even simple assertions have many different forms.

A prepositional modifier complicates things:
Input sentence: A chair is used for sitting on.

Modifiers can change the meaning:
Copper is a good conductor of electricity.
Glass is a bad conductor of electricity.

Cows eat grass.
A bird can fly.
A dog can be a pet.
A person wants love.
Some leaves are green.


A priori vs. Deduced Knowledge
------------------------------
Consider again the following:

_subj(be, capital)
_obj(be, Berlin)
of(capital, Germany)

This sentence references a lot of a-priori knowledge.  We know that
capitals are cities; thus there is a strong temptation to write a
processing rule such as "IF ($var0,capital) THEN ($var0,city)".
Similarly, one has a-priori knowledge that things which have capitals
are political states, and so one is tempted to write a rule asserting
this: "IF (capital_of($var0, $var1)) THEN political_state($var1)".

A current working assumption of what follows is that the normalization
rules will attempt to encode a minimum of a-priori "real-world" knowledge.
Instead, the goal here is to encode linguistic knowledge, and
specifically, linguistic knowledge pertaining to prepositions and
copulas: the copula expresses "is-a" relations, while the preposition
expresses relationships: "has-a", "next-to", "part-of", "made-of", etc.

The hope is that, by encoding the relatively small number of
prepositional relationships, the much larger set of "real-world"
knowledge rules can be deduced (via backward or forward chaining).

Definite vs. Indefinite
-----------------------
There is a subtle semantic difference between triples that describe
definite properites, vs. triples that describe generic properities,
or semantic classes.  Thus, for example, "color_of(sky,blue)" seems 
unambiguous: this is because we know that the sky can only ever have
one color (well, unless you are looking at a sunset!). Consider 
"form_of(clothing, skirt)": this asserts that a skirt is a form_of
clothing, and not that clothing is always a skirt. The form_of
indicates a semantic category.  Similarly, "group_of(people, family)"
asserts that a family is a group_of people, and not that groups of
people are families.

The distinction here seems to be whether or not the modifier was
definite or indefinite: "THE color of ...." vs. "A form of.." or
"A group of..."

XXX This is a real bug/hang-up in the triples processing code: 
being unaware of this distinction seems to cause some triples
to come out "backwards" (i.e. that clothing is always a skirt).
Caution to be used during seme formation!


Rules
-----
Consider again the following:

   Input sentence: "The capital of Germany is Berlin."
   _subj(be, capital)
   _obj(be, Berlin)
   of(capital, Germany)

and we wish to deduce:

   captial_of(Germany, Berlin)

The following processing rule acheives this:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) THEN 
     ^3_$var0_$prep($var2, $var1)

The carats ^ in the pedicate denote 'and'. Dollar signs preceed variable
names. In the predicand, the initial ^3_ denotes the origin of the rule.
(^1_ denotes framenet, ^2_ denotes David Noziglia, and ^3_ denotes Linas).
The above IF-THEN rule is intended to be identical in syntax to the
rules that are already used in the RelEx framing code; i.e. the syntax
is meant to be identical to that of the file "data/frame/mapping_rules.txt"
in the RelEx source tree.

The ! symbol denotes "not". Used in front of a term, it states that the
term must be *absent*, or, if present, must have a truth value of 'false'.
See the section "is-a", below, for an example usage.

The above rule cannot be applied to the following:

   Input sentence: "Berlin is the capital of Germany."
   _subj(be, Berlin)
   _obj(be, capital)
   of(capital, Germany)

because of the constraint that $var0 appear in both the preposition
and the subject.  Proper mangling of the above requires the following
rule:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var1,$var2) THEN 
     ^3_$var1_$prep($var2, $var0)

Notice the connection across var0 and var1 is symmetrically exchanged.


Representing IF...THEN constructs in OpenCog
============================================
The core idea is to find patterns in text, and then create new patterns
as a result. As the simplest example, a "pattern" would be finding all
instances of a noun in some block of text, assuming that all of these
nouns refer to the same thing, and so creating a ConceptNode that
encompases all of these noun instances.  This can be crudely represented
as the pseudo-code:

   IF (for-all parses of all sentences in same document)
       AND (word-instance-1 == noun)
       AND (word-of-word-instance-2 == word-of-word-instance-1)
       AND ...
       AND (word-of-word-instance-k == word-of-word-instance-1)
   THEN (create concept-node encompassing word-instances 1 thru k)

It would be "easiest" to code up above in C++ or Scheme (or Java or
Python or ...) but this missses the point: The opencog system will
need to be able to modify the above rule (or algorithm) based on
learned, statistical experience, for example, by adding more
AND-clauses to refine the action.

Another example: The consistency of this reference assignment can be
checked using the following pseudo-code:

   IF (word-instance-1 is-grouped-wth word-instance-2 in same concept)
      AND (word-instance-1 has property-A)
      AND (word-instance-2 has property-B)
      AND (property-A is inconsistent with property-B)
   THEN (word-instance-1 and word-instance-2 should be ungrouped,
        and are probably distinct concepts)

The above pseudocode would help resolve text such as "Jurate held a red
balloon. Kastytis held a green balloon." The intitial reference
resolution would assign both word instances to the same object-instance
(i.e. assume that both words refer to just one balloon). The consistency
checker would note that the color property is inconsistent, and thus
conclude that these are probably not refering to the same object. (And
thus, the combined-concept should be assigned a truth value close to
"false", and two new, distinct object-instance-concepts should be
created.

The core OpenCog nodes and links to be used to represent such rules are:
   VariableNode  -- to indicate a variable
   ImplicationScopeLink -- to represent an if..then.. relationship.

Below is an example of the use of the ImplicationScopeLink.

   "If the case is near the mouse and the cat is hungry, the cat will
   eat the mouse".

   ImplicationScopeLink
   ___ANDLink
   ______ Inheritance $var0 cat
   ______ Inheritance $var0 hungry
   ______ EvaluationLink
   ___________ Node near
   ___________ ListLink
   _______________VariableNode $var1
   _______________VariableNode $var0
   ______ InheritanceLink $var1 mouse
   ___EvaluationLink
   ______Node eat
   ___________VariableNode $var0
   ___________VariableNode $var1


In practical terms, as the above shows, the encoding of rules will
likely be quite verbose. For the next example, consider two word
instances, using the current RelEx output format.

In the following, we will use the word "axiom" for "rule".
Each such rule has the structure of an implication, in Skolemized form,
with a list of variables up front, an antecedent (the "if" clause),
and a consequent (the "then" clause).  The antecedent is a list of
clauses that must be satisfied, the consequent is a set of nodes to
be created/modified.

   (BindLink
      ; A list of the variables in the "rule" or "axiom".
      ; This list essentially acts as a type declaration for
      ; the variables in this axiom.
      (ListLink
         ; Type declaration: $word-inst-0 is a word instance
         (WordInstanceNode $word-inst-0)
         (WordInstanceNode $word-inst-1)
         (ParseNode $parse-0)
         (ParseNode $parse-1)
         (SentenceNode $sentence-0)
         (SentenceNode $sentence-1)
         (DocumentNode $document)
         (ConceptNode $concept)

         ; The variable $word *must* be a WordNode
         (WordNode $word)
      )

      ; What follows is a conjunction of expressions
      ; that must be satisfied for this "axiom" to hold.
      (AndLink

         ; The word-instance must be nouns.
         (PartOfSpeechLink
            (VariableNode $word-inst-0)
            (DefinedLinguisticConceptNode "noun")
         )
         (PartOfSpeechLink
            (VariableNode $word-inst-1)
            (DefinedLinguisticConceptNode "noun")
         )

         ; The word-instances must refer to the same word.
         (LemmaLink
            (VariableNode $word-inst-0)
            (VariableNode $word)
         )
         (LemmaLink
            (VariableNode $word-inst-1)
            (VariableNode $word)
         )

         ; The word-instances must belong to the same document.
         ; This is done by making sure that they belong to parses,
         ; which belong to sentences, which belong to documents.
         ;
         ; XXX to-do: the number of words in a sentence is variable.
         ; Its not clear how to match this, given the structure below!
         (ReferenceLink
            (ParseNode $parse-0)
            (ListLink
               (VariableNode $word-inst-0)
            )
         )
         (ParseLink
            (ParseNode $parse-0)
            (SentenceNode $sentence-0)
         )
         (ReferenceLink
            (ParseNode $parse-1)
            (ListLink
               (VariableNode $word-inst-1)
            )
         )
         (ParseLink
            (ParseNode $parse-1)
            (SentenceNode $sentence-1)
         )
         (ReferenceLink
            (DocumentNode $document)
            (ListLink
               (SentenceNode $sentence-0)
               (SentenceNode $sentence-1)
            )
         )
      ) ; end of AndLink (the antecedent, or "if" clause)
      ; Above is the conjunction of clauses that must hold

      ; Next the consequent, or "then" clause.
      ; Create a single concept, which encompases each of these word
      ; instances, implying that they all refer the to same overall
      ; concept.

      ; XXX somehow generate a new UUID for this new concept!
      ; use a combo of the word, and the document, to help identify it.
      (ConceptNode $concept)
      (ExtensionalInheritanceLink
         (ConceptNode $concept)
         (WordInstanceNode $word-inst-0)
      )
      (ExtensionalInheritanceLink
         (ConceptNode $concept)
         (WordInstanceNode $word-inst-1)
      )
   )


Evaluator, Application of Rules
================================
The above-described "rules" or "templates" perform transformations on
hypergraphs. There needs to be an "apply" function to apply these rules
to document hypergraphs. Here, "Apply" is meant to have the usual
comp-sci overtones of function application, see, for example, the
Wikipedia article, or SICP chapter 4.  There are several ways in which
the "apply" function might be implemented.
  
Possibilities:
1) Make use of PLN forward or backward chainers to perform the
   application.
2) Adapt existing "src/query" code, which does general pattern matching,
   (i.e. is capable of matching to VariableNodes) to be able to apply
   above rules.

At this time, the foreward & backwards chainers are designed for a
slightly different purpose; they are not really meant to be a generic
"Apply" function. They are also missing several syntactical constructs
needed for "apply" to work:

  a) Ability to declare the type of a variable (The core assumption here
     is that OpenCog should be a strongly-typed langauge)
  b) The inability to create new atoms and links, as needed.

On the other side, the chainers do correctly propagate truth values;
whereas the query code is truth-value agnostic.  Open question: XXX How
should the Apply function handle truth values?

XXX While we're at it: should define a lambda. This would make
everything *sooo* much easier. Note that the chainers do not have
support for lambda at this time.


Encoding as an ImplicationScopeLink
-----------------------------------
The above rules are to be encoded as ImplicationScopeLinks. Thus, the rule

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) THEN 
     ^3_$var0_$prep($var2, $var1)

is meant to be a short-hand for:

   ImplicationScopeLink
      AndLink
         EvaluationLink
            DefinedLinguisticRelationshipNode "_subj"
            ListLink
               ConceptNode "be"
               VariableNode "$var0"
         EvaluationLink
            DefinedLinguisticRelationshipNode "_obj"
            ListLink
               ConceptNode "be"
               VariableNode "$var1"
         EvaluationLink
            VariableNode "$prep"
            ListLink
               VariableNode "$var0"
               VariableNode "$var2"
      EvaluationLink
         DefinedLinguisticRelationshipNode ($var0 . "_" . $prep)
         ListLink
            VariableNode "$var2"
            VariableNode "$var1"

Note the snag of concatenating strings.  The only easy way out of
this appears to be to salt the atomspace with contractions.  Thus,
the atomspace would contain a relation:

   EvaluationLink
      DefinedLinguisticRelationshipNode "capital_of"
      ListLink
         ConceptNode "capital"
         DefinedLinguisticRelationshipNode "of"

The above ImplicationScopeLink would then include a fourth clause in the
predicate:

   EvaluationLink
      VariableNode $phrase
      ListLink
         VariableNode $var0
         VariableNode $prep

while the implicand would be written as:

   EvaluationLink
      VariableNode $phrase
      ListLink
         VariableNode "$var2"
         VariableNode "$var1"

The above would be expressed directly in the rules syntax as:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) 
       ^ $phrase($var0, $prep)
       THEN ^3_$phrase($var2, $var1)

There is one additional complication to the above. The natural output of
Relex puts a buffer between words and concepts. Thus, an example of the 
output is:

(EvaluationLink
   (DefinedLinguisticRelationshipNode "of")
   (ListLink
      (WordInstanceNode "capital@cd67b274-9957-463c-aad8-422bec133613")
      (WordInstanceNode "Germany@75f2f934-91a7-47ba-9bcc-e2a3340c9076")
   )
)

The word instances are related to their lemmatized forms:

(LemmaLink
   (WordInstanceNode "capital@cd67b274-9957-463c-aad8-422bec133613")
   (WordNode "capital")
)
(LemmaLink
   (WordInstanceNode "Germany@75f2f934-91a7-47ba-9bcc-e2a3340c9076")
   (WordNode "Germany")
)

Thus, the implication predicate needs to bind word-instances to word
nodes. 

There is another problem: ImplicationScopeLinks cannot be used to change
the type of a node. Thus, while the examples above made reference to
ConceptNodes, the actual RelEx LemmaLinks specify WordNodes.  There's 
no immediate, direct way to turn WordNodes into ConceptNodes; this 
will be fudged for now.

Another problem to note: it only makes sense to extract relations
between words in a sentence (or across sentences, if reference resolution
is implemented).  However, there is currently no natural way to specify
that the searches should be performed only on a certain subset of the
atom space -- e.g. to perform the matching only on terms that belong to 
one sentence.  Thus, at this time, each frame rule contains explicit
directives that force all matches to lie within one sentence. So, for
example:

# IF _subj(be,$var0) ^ _obj(be,$var1)
      ^ $prep($var0,$var2)              ; preposition 
      ^ %LemmaLink($var0,$word0)        ; word of word instance
      ^ $phrase($word0, $prep)          ; convert to phrase
      ^ %WordInstanceLink($var0,$sent)  ; $var0 and $var1 must be
      ^ %WordInstanceLink($var1,$sent)  ; in the same sentence
      THEN ^3_$phrase($var2, $var1) 

Note the use of WordInstanceLink to force both words to belong to 
the same sentence.

R-expressions
-------------
The above examples are written in an application-specific language that
is an extension of the way that the Frame rules are written in RelEx. 
Although the RelEx frame rules are sufficent to do processing in RelEx,
they don't provide enough flexibility to work well in OpenCog, and so 
extesnions sub as %WordInstanceLink and %LemmaLink and so on are needed.

The  perl script "rules-to-implications.pl" will convert rules written
in this syntax into OpenCog ImplicationScopeLinks.  This script could be
useful for importing the Frame rules into OpenCog.

However, even with these extensions, problems arose. The most serious 
problem was that some of the variables needed to be scoped: if they
range too freely, they will match too many OpenCog hypergraphs that
are quite irrelevant to the problem (e.g. they might match
EvaluationLink's that describe the Link-Grammar linkages, which are 
unwanted at this stage of processing.)  Another problem is that the
"rules-to-implications.pl" perl script started life as an ad-hoc script,
and has become unmaintainable as features were added. It should probably
have been created as a lex/yacc program from the get-go.

Finally, the IF..THEN syntax very explicitly presumes that RelEx
expressions appear in the IF clause.  Howeve, some users (e.g.
embodiment) need to have similar functions but have other kinds of 
hypergraphs appearing on the "input" side. 

To step around these problems, a variant of the above was written in
pure scheme, and is encoded in the file "rules.scm".  RelEx expressions
are converted into "r-expressions" which hold both clauses and lists of
variables. As a final step, an r-expression is converted into a
BindLink contiaing variable declarations and an ImplicationScopeLink.

New code should use "rules.scm". The perl script "rules-to-implications.pl"
should be avoided, except possibly during a port of RelEx to OpenCog.


Demonstration run
-----------------
(See also HOWTO below)

The file "rules.scm" contains the current set of rules.  The
opencog3.conf configuration file should be modified and the following
clauses added to the SCM_PRELOAD list:

        nlp/triples/preps.scm,
        nlp/triples/prep-maps.scm,
        nlp/triples/rule-tools.scm,
        nlp/triples/prep-rules.scm,
        nlp/triples/rules.scm,
        nlp/triples/triples-pipeline.scm,

Text that was parsed by RelEx, and output in opencog format, must be 
loaded, by running "./load-examples.sh".

Sentences must be pre-processed by running the following:
   (cog-bind prep-rule-0)
and again for prep-rule 1,2,3 inclusive.

Implications can be processed with the scheme interpreter, using the 
ad-hoc command:

  (cog-bind stmt)

where the stmt is the implication to evaluate. So, for example, 

  (cog-bind triple-rule-0)

This will search the entire contents of the atomtable, looking for any
hypergraphs that match the predicate of the implication.  The output is
a list of all possible implicands: thus, for example:

guile> (cog-bind triple-rule-0)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "capital_of")
    (ListLink (WordInstanceNode "Germany@3cdca1f8-adf4-4532-a2d6-622da3f43ce6")
       (WordInstanceNode "Berlin@a0d168f7-3735-48a1-b603-33dd0fc95228"))))

guile> (cog-bind triple-rule-1)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "capital_of")
    (ListLink (WordInstanceNode "Portugaul@36d41058-3dc8-4e6c-82b9-300a5f48e283")
       (WordInstanceNode "Lisbon@9d5031b1-5caf-48eb-ae7c-b3a89bb11381"))))

guile> (cog-bind triple-rule-2)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "color_of")
    (ListLink (WordInstanceNode "sky@f3924dad-81a0-4967-81c8-900e31254f74")
       (WordInstanceNode "blue@df54a7e9-1fb2-4643-be97-ca6ee1e7a359"))))

Note that the rule numbering is subject to change.


HOWTO
-----
(See also "Demonstration Run" above.)

How to run the current code in example/demo/debug mode:
-- start cog-server
-- run load-examples.sh  to load the example sentences.
-- Enter the scheme shell
-- run (cog-bind prep-rule-0) through
   (cog-bind prep-rule-3) 
   These is a require step to perform some initial setup.
-- run (cog-bind triple-rule-0) through
   (cog-bind triple-rule-7) and observe results.
-- That's all. The results printed above are a "demo" of the
   kinds of things that the rules can currently produce.

Next step:
-- Download the MIT ConceptNet corpus.
-- This corpus is in N3 format; strip out sentences by 
   running "nlp/seme/conceptnet.pl"
-- Parse the sentences using RelEx, generate opencog output.
   (There are about 252870 sentences in the June 2008 dump.)
-- Create a presistence repository for accumulating results.
   (at this time, create a new SQL db)
       createdb triples
       cat opencog/persist/atom.sql | psql triples
-- Run cogserver
-- open the database created above
-- Edit nlp/seme/config.scm and change file path to parsed sentences.
   xx xx move these docs to the seme directory
-- Enter the scheme shell

XXXXXXXXXXXXXX TEMPORARILY BROKEN, input sentences must be linked to
AnchorNode "# APPLY TRIPLE RULES" via list link to apply.

-- run command (do-triples n) where n is the number of files
   to process. XXX this command has been moved to chatbot dir ... 

Alternately, load data in some other way, and then
issue the scheme expression (fire-all-triple-rules) to create
the assorted triples.


Notes
-----
6:38 to load part 1 (3693 sentences)
5:33 to load part 1
6:51 to load part 1
0:30 to create prep maps in bulk
first threee take <1min each.
4th took 18 mins
rest took < 1min
27:04 including the load time. to process 3693 sentences.
This lead to 3841 rows.

alt: sentence at a time: 13:18 total time.

part 2: start at 17:02 end 17:53 elapsed time =51 minutes w/ 18 mins
cpu time.

part 3: start 10:25 end 10:58 elapsed=33 mins w/ 10:56 cpu time.


References:
-----------
[APPL] Apply: See
   http://en.wikipedia.org/wiki/Apply
   Also, Abelson, Sussman, SICP, section 4.1 the Meta-circular evaluator
   http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-26.html

[IMPL] Implication: See
   http://en.wikipedia.org/wiki/Logical_implication

[WP-RDF] Resource Description Framework
     http://en.wikipedia.org/wiki/Resource_Description_Framework

Alexander Yates and Oren Etzioni.
[http://www.cis.temple.edu/~yates/papers/resolver-jair09.pdf
Unsupervised Methods for Determining Object and Relation Synonyms on
the Web]. Journal of Artificial Intelligence Research 34, March,
2009, pages 255-296.

YAGO triple store:
http://www.mpi-inf.mpg.de/yago-naga/yago/

Boris Katz, Gary Borchardt and Sue Felshin
Syntactic and Semantic Decomposition Strategies for Question
Answering from Multiple Resources
Proceedings of the AAAI 2005 Workshop on Inference 2005 - aaai.org

