
                    Natural Language Processing
                    ---------------------------

This directory contains an assortment of natural language processing
subsystems, primarily focused on the English language). This includes
language learning code, logical reasoning on facts extracted from
sentences, reference resolution, question answering, natural
language output (generation of syntactically valid sentences),
a chatbot interface, and some AIML interfaces.

How-To
======
The current code "doesn't do anything yet"; rather, it is a platform for
running experiments. Thus, what is contained here should be thought of
as a "bag of parts".  It is up to you to figure out what these parts
are, and to assemble them into something meaningful.  Some fragile
examples have been constructed (e.g. the code in the old-chatbot
directory) but its up to you to do better.

Currently, there are three basic experimental flows that are possible:
the chatbot process, the language-learning process, and the
word-sense-disambiguation (WSD) process.  See the "learn" directory for
more about language learning. See the wsd directory for more about wsd.


Subdirectories (in alphabetical order)
======================================
aiml2oc
-------
Prototype for converting AIML XML into opencog "atomese", so that a
simple opencog script could run AIML dialogs. Under developemnt,
incomplete.

anaphora
--------
Code that picks out pronouns (he, she, it) and offers up a list of
plausible candidates that these might refer to.

chatbot
-------
Scripts for running a chatbot.  Prototypes, incomplete.

diary
-----
Research notes.

irc
---
Interfaces to IRC; provide an easy way to connect opencog to IRC.

learn
-----
Langauge learning code. Goal is to learn any language at all, given
some sufficiently large corpus.  Experiment is in progress, results
are promising but inconclusive. Starved for time.

lg-dict
-------
Code to convert the Link Grammar dictionaries to "atomese". These are
used to construct and validate generated sentences for correct syntax.

microplanning
-------------
A planner for generating natural language sentences from a bag of
dependency-grammar relations. That is, given a set of dependencies
that express an idea, the planner will create a series of sentences that
express the idea, are syntactically correct, are of appropriate length,
and use pronouns in an appropriate way.


old-chatbot
-----------
The old-chatbot directory contains some code to tie opencog NLP
processing to chat systems, and particularly, to IRC chat.  Provides
a high-level implementation of a simple, hard-coded question-answering
system, resting on the foundations of "seme" and "triples".  It worked,
but had some design difficulties.

relex2logic
-----------
Convert RelEx dependency relations to logical predicates/assertions. The
point here is that PLN can only reason on logical forms, and so we need
to convert dependencies into (first-order, probabilistic) logic forms.

scm
---
The scm directory contains miscellaneous scheme scripts of general
utility for NLP work. This includes scripts for pulling out link-grammar
disjuncts from parse data.

sureal
------
Surface realization -- the lowest level portion of natural language
generation. Works in conjunction with the microplanner to build
sentences.

types
-----
Scripts specifying NLP-specific atom types.

viterbi
-------
A barely-started, mostly abandoned attempt to create a viterbi parser
for link-grammar (actually, a port of the partly-implemented viterbi
parser in the link-grammar code base, which is more functional than
this one, but is still broken.)

wsd
---
The wsd directory contains code that implements the Rada Mihalcea
word-sense disambiguation algorithm.  The Mihalcea algorithm assigns
senses to the words in a sentence, and constructs links between these
different senses. The links are weighted by a word-sense similarity
measure. The result is a graph whose vertices are word-senses, and
whose edges are these links.  The graph is essentially just a Markov
chain, and is solved as such, looking for a stationary vector of
probabilities for the word-sense vertices. The vertices with the
highest scores are then the most likely meaning for a word.

wsd-post
--------
The wsd-post directory contains code for generating datasets which may
be used for extremely fast (but partial) word-sense disambiguation,
based on grammatical (syntactical) usage. Generating the data-sets can
take cpu-month to cpu-years; the table-lookup can be done in milli or
microseconds.


======================================================================

Input file format
-----------------
This style of input may be produced in one of two ways. It is produced
directly by RelEx, when using the opencog output format: the -o flag
appended to the `relex.RelationExtractor` executable. The other way is
indirect, but can be considerably more convenient: First, parse text
using the `relex.WebFormat` module, to create the "compact file format".
Then, use the `relex/src/perl/cff-to-opencog.pl` perl script to convert
this to the final output.


A Side-note About Syntactic Sugar
===================================
This has been said before, but it bears repeating. Consider the node
type WordInstanceNode, for example:

    (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")

This custom-defined node type should be thought of as syntactic sugar
for the more "primitive" graph:

   (InheritenceLink
        (ConceptNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
        (ConceptNode "WordInstance")
    )

The above InheritenceLink essentially assigns a "type" to the word
instance. This type can be used in the same way that types are
ordinarily used in other programming languages. When managing
hypergraphs, it is almost always easier and faster to locate,
manipulate and delete narrowly typed atoms.

Similarly, for links, we use the syntactic sugar

    (PartOfSpeechLink
        (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
        (DefinedLinguisticConceptNode "noun")
    )

which stands for the more "primitive" construct:

    (EvaluationLink
        (PredicateNode "PartOfSpeech"
            (ListLink
                (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
                (DefinedLinguisticConceptNode "noun")
            )
        )
    )

Notationally, these forms should be considered to be "equivalent"
although there is a bunch of actual code that depends on the one or
the other, and cannot freely intermingle these cases.

Not everything in the RelEx export gets its own specially-declared
node or link type. Those that do not are explicitly declared in the
file "src/nlp/scm/type-definitions.scm"

======================================================================
References:
-----------
"To verbize one's nouns" -- the concept of "Lexical Implication Rules":
N. Ostler, B.T.S.Atkins, "Predictable Meaning Shift: Some Linguistic
Properties of Lexical Implication Rules", (1991) Proceedings of the
First SIGLEX Workshop on Lexical Semantics and Knowledge Representation
